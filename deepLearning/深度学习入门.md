## 前言


## 第一章

## 第二章

## 第三章


## 第四章

- 机器学习中使用的数据集分为训练数据和测试数据；
- 神经网络用测试数据进行学习，并用测试数据评价学习到的模型的泛化能力；
- 神经网络的学习以损失函数为指标，更新权重参数，以使损失函数的值减小；
- 利用某个给定的微小值的差分求导的过程，称为数值微分；
- 利用数值微分，可以计算权重参数的梯度；
- 数值微分虽然费时间，但是实现起来很简单。稍微复杂一些的误差反向传播法可以高速地计算梯度；

## 第五章

## 误差反向传播法
正确理解误差反向传播法，有两种方法：一种是基于数学式，另一种是基于计算图。

通过计算图来理解误差反向传播法这个想法，参考了Andrej Karpathy的博客[4]和他与Fei-Fei Li教授负责的斯坦福大学的深度学习课程CS231n

- 正向传播：
正向传播是从计算图出发点到结束点的传播。
- 反向传播
反向传播就是从计算图的结束点到出发点的传播。
- 局部计算
计算图将复杂的计算方式分割成简单的局部计算，和流水线作业一样，将局部计算的结果传递给下一个节点。
- 使用计算图的原因
使用计算图，可以通过正向传播和反向传播高效计算各个变量的导数值。

## 链式法则

如果某个函数由符合函数表示，则该复合函数的导数可以用构成符合函数的某个函数的导数的乘积表示。

## 反向传播

1. 加法的反向传播是将上游的值原封不动的传输到下游；
2. 乘法的反向传播会将上游的值乘以正向传播时的输入信号的“翻转值”后传输给下游。

z = xy，正向传播时信号是x的话，反向传播时则是y；正向传播时信号是y的话，反向传播时则是x。

加法的反向传播只是将上游的值传给下游，并不需要正向传播的输入信号。但是，乘法的反向传播需要正向传播时的输入信号值。因此，实现乘法节点的反向传播时，要保存正向传播的输入信号。


## 简单层的是心啊
1. 计算图的乘法节点称为“乘法层”，加法节点称为“加法层”。
2. 我们把构建神经网络的“层”实现为一个类，这里所说的“层”时神经网络中功能的单位。比如，负责sigmoid函数的sigmoid、负责矩阵乘积的affine等，都是以层为单位进行实现。

## 总结