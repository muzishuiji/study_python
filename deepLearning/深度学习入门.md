## 前言


## 第一章

## 第二章

## 第三章


## 第四章

- 机器学习中使用的数据集分为训练数据和测试数据；
- 神经网络用测试数据进行学习，并用测试数据评价学习到的模型的泛化能力；
- 神经网络的学习以损失函数为指标，更新权重参数，以使损失函数的值减小；
- 利用某个给定的微小值的差分求导的过程，称为数值微分；
- 利用数值微分，可以计算权重参数的梯度；
- 数值微分虽然费时间，但是实现起来很简单。稍微复杂一些的误差反向传播法可以高速地计算梯度；

## 第五章

### 误差反向传播法
正确理解误差反向传播法，有两种方法：一种是基于数学式，另一种是基于计算图。

通过计算图来理解误差反向传播法这个想法，参考了Andrej Karpathy的博客[4]和他与Fei-Fei Li教授负责的斯坦福大学的深度学习课程CS231n

- 正向传播：
正向传播是从计算图出发点到结束点的传播。
- 反向传播
反向传播就是从计算图的结束点到出发点的传播。
- 局部计算
计算图将复杂的计算方式分割成简单的局部计算，和流水线作业一样，将局部计算的结果传递给下一个节点。
- 使用计算图的原因
使用计算图，可以通过正向传播和反向传播高效计算各个变量的导数值。

### 链式法则

如果某个函数由符合函数表示，则该复合函数的导数可以用构成符合函数的某个函数的导数的乘积表示。

### 反向传播

1. 加法的反向传播是将上游的值原封不动的传输到下游；
2. 乘法的反向传播会将上游的值乘以正向传播时的输入信号的“翻转值”后传输给下游。

z = xy，正向传播时信号是x的话，反向传播时则是y；正向传播时信号是y的话，反向传播时则是x。

加法的反向传播只是将上游的值传给下游，并不需要正向传播的输入信号。但是，乘法的反向传播需要正向传播时的输入信号值。因此，实现乘法节点的反向传播时，要保存正向传播的输入信号。


### 简单层的实现
1. 计算图的乘法节点称为“乘法层”，加法节点称为“加法层”。
2. 我们把构建神经网络的“层”实现为一个类，这里所说的“层”时神经网络中功能的单位。比如，负责sigmoid函数的sigmoid、负责矩阵乘积的affine等，都是以层为单位进行实现。

## 函数激活层的实现

1. 将构成的神经网络的层实现为一个类，实现激活函数Relu层和Sigmoid层。
2. Relu层的作用就像电路的开关一样，正向传播时，有电流通过的话，就将开发设为ON。没有电流通过的话，就将开发设为OFF。反向传播时，开关为ON的话，电流会直接通过。开关为OFF的话，则不会有电流通过。
3. 矩阵的乘积运算中对应维度的个数要保持一致。

X        *      W     =     O
(2,)          (2,3)        (3,)

4. 神经网络的正向传播中进行的矩阵的乘积运算在几何领域被称为“仿射变换”。神经网络里将仿射变换的处理实现为Affine层。

5. 几何中，仿射变换包括一次性变换和一次平移，分别对应神经网络的加权和运算与加偏置运算。

6. 矩阵的乘积（dot节点）的反向传播可以通过组建使矩阵对应维度的元素个数一致的乘积运算而推导出来。

7. 神经网络中进行的处理有推理和学习两个阶段。神经网络的推理通常不使用Softmax层。神经网络进行推理时，会将最后一个affine层的输出作为识别结果。神经网络中未被正规化的输出结果有时称为“得分”。当神经网络的推理只需要给出一个答案的情况下，因为此时只对得分最大值感兴趣，所以不需要Softmax层，神经网络的学习阶段需要Softmax层。

8. 使用交叉熵误差作为Softmax函数的损失函数后，反向传播得到(y1 - t1, y2 - t2, y3 - t3)这样“漂亮”的结果。实际上，这样“漂亮”的结果并不是偶然的，而是为了得到这样的结果，特意设计了交叉熵误差函数。回归问题中输出层使用“恒等函数”，损失函数使用“平方和误差”，也是出于同样的理由。也就是说，使用“平方和误差”作为“恒等函数”的损失函数，反向传播才能得到(y1 - t1, y2 - t2, y3 - t3)这样“漂亮”的结果。

9. 微分差值法通常用来衡量误差反向传播法计算结果的准确性，这一过程也称为梯度确认。

数值微分和误差反向传播法的计算结果之间的误差为0是很少见的。这是因为计算机的计算精度有限（比如，32位浮点数）。受到数值精度的限制，两者的误差一般不会为0，如果实现正确的变化，这个误差是一个接近0的很小的值。如果这个值很大，则说明误差反向传播法的实现存在错误。

### 第五章总结

1. 以层为单位实现神经网络中的处理，如ReLU层，softmax-with-loss层、Affine层等，这些层实现了forward和backward方法，通过将数据正向和反向的传播，可以高效的计算权重参数的梯度。
2. 通过使用层进行模块化，神经网络中可以自由的组装层，轻松的构建出自己喜欢的网络。
3. 使用计算图，可以直观的把握计算过程。
4. 计算图的节点是由局部计算构成的，局部计算构成全局计算。
5. 通过比较数值微分和误差反向传播法的结果，可以确认误差反向传播法的实现是否正确（梯度确认）。

## 总结